{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Group by is being handled as part of this code below\n",
    "\n",
    "\n",
    "### About moz parser\n",
    "SQL is a familiar language used to access databases. Although, each database vendor has its quirky implementation, the average developer does not know enough SQL to be concerned with those quirks. This familiar core SQL (lowest common denominator, if you will) is useful enough to explore data in primitive ways. It is hoped that, once programmers have reviewed a datastore with basic SQL queries, and they see the value of that data, they will be motivated to use the datastore's native query format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moz_sql_parser import parse\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate_select_dict will give a dictionary where all the base columns + udf and alias will be seggregated, it can accomodate 4 level of UDF for now, it is basically the driver of the select ang group part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_select_dict(select_list):\n",
    "    column_list = []\n",
    "    for column_dict in select_list:\n",
    "        if column_dict==\"*\":\n",
    "            pass\n",
    "        elif type(column_dict['value'])== str:\n",
    "            if '.' in column_dict['value']:\n",
    "                column_value = column_dict['value'].split('.')[1]\n",
    "                column_table = column_dict['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"base_col\":column_value,\"udf\":\"\",\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "            else:\n",
    "                column_value = column_dict['value']\n",
    "                column_table=\"\"\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"base_col\":column_value,\"udf\":\"\",\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "            \n",
    "            \n",
    "        elif type(column_dict['value'])== dict:\n",
    "            if '.' in column_dict['value']:\n",
    "                column_value = column_dict['value'].split('.')[1]\n",
    "                column_table = column_dict['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                colsttmp={\"base_col\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                column_list.append(colsttmp)\n",
    "            else:\n",
    "                column_value=column_dict['value']\n",
    "                final_col=[]\n",
    "                for k,v in column_dict['value'].items():\n",
    "                    if k==\"case\":\n",
    "                        pass\n",
    "                    else:\n",
    "                        udf=k\n",
    "                        cols=v\n",
    "                        if type(cols)==str:\n",
    "                            if '.' in cols:\n",
    "                                col_name =cols.split('.')\n",
    "                                final_col.append(col_name[1])\n",
    "                            else:\n",
    "                                final_col.append(cols)\n",
    "                        elif type(cols)==dict:\n",
    "                            for k,v in cols.items(): ###########needs to be coded\n",
    "                                udf=udf+\",\"+k\n",
    "                                cols=v\n",
    "                                for i in cols:\n",
    "                                    final_col.append(i)\n",
    "                                \n",
    "                        else:\n",
    "                            for i in cols:\n",
    "                                if type(i)==str:\n",
    "                                    if '.' in i:\n",
    "                                        column_name= i.split('.')\n",
    "                                        col_name= column_name[1]\n",
    "                                        final_col.append(col_name)\n",
    "                                    else:\n",
    "                                        final_col.append(i)\n",
    "                        \n",
    "                                elif type(i)==int:\n",
    "                                    final_col.append(i)\n",
    "                    \n",
    "                                elif type(i)==dict: ## here adjustments needs to be done\n",
    "                                    new_dict=i\n",
    "                                    for k,v in new_dict.items():\n",
    "                                        extra_udf=k\n",
    "                                        udf=udf+\",\"+extra_udf\n",
    "                                        cols=v\n",
    "                                        if type(cols)==list:  ## for list\n",
    "                                            for i in cols:\n",
    "                                                if type(i)==str:\n",
    "                                                    if '.' in i:\n",
    "                                                        splitter= i.split('.')\n",
    "                                                        part1=splitter[0] \n",
    "                                                        part2=splitter[1]\n",
    "                                                        final_col.append(part2)\n",
    "                                                    else:\n",
    "                                                        final_col.append(i)\n",
    "                                                else:\n",
    "                                                    final_col.append(i)\n",
    "                                        elif type(cols)==str:  ## for str\n",
    "                                            if '.' in cols:\n",
    "                                                splitter= cols.split('.')\n",
    "                                                part1=splitter[0] \n",
    "                                                part2=splitter[1]\n",
    "                                                final_col.append(part2)\n",
    "                                            else:\n",
    "                                                final_col.append(cols)\n",
    "                                        elif type(cols)==dict:  ## for dict\n",
    "                                            for k,v in cols.items():\n",
    "                                                third_udf=k\n",
    "                                                udf =udf+\",\"+third_udf\n",
    "                                                cols=v\n",
    "                                                for i in cols:\n",
    "                                                    if '.' in i:\n",
    "                                                        splitter= i.split('.')\n",
    "                                                        part1=splitter[0] \n",
    "                                                        part2=splitter[1]\n",
    "                                                        final_col.append(part2)\n",
    "                                                    else:\n",
    "                                                        final_col.append(i)\n",
    "                                        else:\n",
    "                                            pass\n",
    "                                            \n",
    "                                else:\n",
    "                                    pass\n",
    "                    try:\n",
    "                        alias=column_dict['name']\n",
    "                    except:\n",
    "                        alias=\"\"\n",
    "                    colltmp={\"base_col\":final_col, \"udf\":udf,\"Alias\":alias}\n",
    "                    column_list.append(colltmp)\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the required UDF's are incorporated here, this list will be continued further..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coalesce_udf(columns,final_df,alias,final_columns,len_udf):\n",
    "    coalesce_filler=str(columns[-1])\n",
    "    if len_udf==1:\n",
    "        query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".\"+final_columns[0]+\".fillna(value=\"+coalesce_filler+',inplace=True)'\n",
    "    else:\n",
    "        query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".\"+alias+\".fillna(value=\"+coalesce_filler+',inplace=True)'\n",
    "    return query\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multiplication_udf(final_columns,alias,final_df):\n",
    "#     print(final_columns)\n",
    "#     print()\n",
    "#     list_of_col = [\"row.\"+a for a in final_columns]\n",
    "#     cols='*'.join(list_of_col)\n",
    "#     query = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+'.apply(lambda row: '+cols+', axis = 1)'\n",
    "#     return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_udf(final_columns,alias,final_df):\n",
    "    final_columns =[a for a in final_columns if a!=0]\n",
    "    type_instance=all(isinstance(item, str) for item in final_columns)    \n",
    "    if type_instance ==True:\n",
    "        str_list = [a for a in final_columns if type(a)==str]\n",
    "        list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "        final='*'.join(list_of_col)\n",
    "        result =final_df+\"['\"+alias+\"']=\"+final\n",
    "        return result\n",
    "    \n",
    "    elif type_instance ==False:\n",
    "        str_list = [a for a in final_columns if type(a)==str]\n",
    "        list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "        cols='*'.join(list_of_col)\n",
    "        int_list = [str(a) for a in final_columns if type(a)==int or type(a)==float]\n",
    "        cols1='*'.join(int_list)\n",
    "        final = cols+\"*\"+cols1\n",
    "        result =final_df+\"['\"+alias+\"']=\"+final\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic sum functionality of query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_initial_udf(columns,final_df,alias):\n",
    "    columns=columns[0]\n",
    "    query= final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year and month udf's are being handled here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_month_udf(final_df,alias,udf,final_columns):\n",
    "    query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\"[`\"+final_columns[0]+\"`]\"+\".dt.\"+udf+\")\"\n",
    "    return query\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Literal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literals_adjust(final_df,columns,alias):\n",
    "    \"\"\"add new column to pandas dataframe with default value\"\"\"\n",
    "    columns=columns[0]\n",
    "    query =final_df+\"[`\"+alias+\"`]\"+\"=\"+\"`\"+columns+\"`\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns=['_name_', 2,2]\n",
    "# final_df=\"df\"\n",
    "# alias =\"a1\"\n",
    "# #df['state_substring'] =df['city'].str[2:4]\n",
    "# #f['state_substring'] =df['city'].str[1:]\n",
    "\n",
    "# if len(columns)==3:\n",
    "#     start_index = columns[1]-1\n",
    "#     end_index   = columns[1]+start_index\n",
    "#     col = columns[0]\n",
    "#     text_formed = final_df+\"['\"+alias+\"']=\"+final_df+\"['\"+col+\"'].str[\"+str(start_index)+\":\"+str(end_index)+\"]\"\n",
    "#     print(text_formed)\n",
    "# elif len(columns)==2:\n",
    "#     col=columns[0]\n",
    "#     start_index=columns[1]-1\n",
    "#     text_formed = final_df+\"['\"+alias+\"']=\"+final_df+\"['\"+col+\"'].str[\"+str(start_index)+\":]\"\n",
    "#     print(text_formed)\n",
    "# else:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substring_udf(columns,final_df,alias):\n",
    "    if len(columns)==3:\n",
    "        start_index = columns[1]-1\n",
    "        end_index   = columns[1]+start_index\n",
    "        col = columns[0]\n",
    "        text_formed = final_df+\"['\"+alias+\"']=\"+final_df+\"['\"+col+\"'].str[\"+str(start_index)+\":\"+str(end_index)+\"]\"\n",
    "        return text_formed\n",
    "    elif len(columns)==2:\n",
    "        col=columns[0]\n",
    "        start_index=columns[1]-1\n",
    "        text_formed = final_df+\"['\"+alias+\"']=\"+final_df+\"['\"+col+\"'].str[\"+str(start_index)+\":]\"\n",
    "        return text_formed\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distinct or unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_unique(final_df,alias,udf,final_columns):\n",
    "    if alias==\"\":\n",
    "        final_fcol=final_columns[0]\n",
    "        query =final_df+\"[`\"+final_fcol+\"`]\"+\"=\"+final_df+\"[`\"+final_fcol+\"`].unique()\"\n",
    "    else:\n",
    "        final_fcol=final_columns[0]\n",
    "        query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\"[`\"+final_fcol+\"`].unique()\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping columns , this will return all the columns which needs to be grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_columns(group_section):\n",
    "    list1=[]\n",
    "    if 'groupby' in query_dict.keys():\n",
    "        if type(group_section)==list:\n",
    "            for i in group_section:\n",
    "                values =i['value']\n",
    "                list1.append(values)\n",
    "        elif type(group_section)==dict:\n",
    "            for k,v in group_section.items():\n",
    "                list1.append(v)\n",
    "    else:\n",
    "        pass\n",
    "    return list1\n",
    "#grouped_columns(group_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column on which group by needs to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not there\n",
    "def group_to_be_applied_on(sql_dict):\n",
    "    list_col=[]\n",
    "    for i in sql_dict:\n",
    "        all_udf = i['udf']\n",
    "        udf_splitter = all_udf.split(',')\n",
    "        list_of_agg=['sum','min','max','avg','mean','count']\n",
    "        for agg in list_of_agg:\n",
    "            if agg in i['udf']:\n",
    "                agg_cols = i['Alias']\n",
    "                list_col.append(agg_cols)\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "    return list_col\n",
    "#group_to_be_applied_on(sql_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function will do the group by and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_func(final_df,query_dict,grp_cols,alias,udf,final_columns):\n",
    "    if 'groupby' in query_dict.keys():\n",
    "        final_fcol=final_columns[0]\n",
    "        grp_by = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".groupby(\"+str(grp_cols)+\")\"+\"[`\"+alias+\"`]\"+\".agg(\"+udf+\")\"\n",
    "    return grp_by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below function will return the pandas converted queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_constructor(final_df,grp_cols,sql_dict,group_agg):\n",
    "    query_list=[]\n",
    "    for list_elements in sql_dict:\n",
    "        #print(list_elements)\n",
    "        columns = list_elements['base_col']\n",
    "        if columns!='*':\n",
    "            if columns!=[]:\n",
    "                #final_columns =[s for s in columns if type(s)==str]\n",
    "                final_columns =[s for s in columns]\n",
    "                alias=list_elements['Alias']\n",
    "                udf=list_elements['udf']\n",
    "                if list_elements['udf']!='':\n",
    "                    udf_splitter = list_elements['udf'].split(',')\n",
    "                    len_udf =len(udf_splitter)\n",
    "                    if  len_udf==1 and udf==\"coalesce\":\n",
    "                        query= coalesce_udf(columns,final_df,alias,final_columns,len_udf)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf==1 and udf==\"mul\":\n",
    "                        query=multiplication_udf(final_columns,alias,final_df)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf==1 and udf==\"sum\":\n",
    "                        query= sum_initial_udf(columns,final_df,alias)\n",
    "                        query_list.append(query)\n",
    "                        query= group_by_func(final_df,query_dict,grp_cols,alias,udf,final_columns)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf ==1 and udf==\"year\":\n",
    "                        query=year_month_udf(final_df,alias,udf,final_columns)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf ==1 and udf==\"month\":\n",
    "                        query=year_month_udf(final_df,alias,udf,final_columns)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf==1 and udf ==\"literal\":\n",
    "                        query=literals_adjust(final_df,columns,alias)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf==1 and udf ==\"distinct\":\n",
    "                        query = distinct_unique(final_df,alias,udf,final_columns)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf==1 and udf==\"count\":\n",
    "                        query= sum_initial_udf(columns,final_df,alias)\n",
    "                        query_list.append(query)\n",
    "                        query= group_by_func(final_df,query_dict,grp_cols,alias,udf,final_columns)\n",
    "                        query_list.append(query)\n",
    "                    elif len_udf==1 and udf==\"substring\":\n",
    "                        query = substring_udf(final_columns,final_df,alias)\n",
    "                        query_list.append(query)\n",
    "                        \n",
    "                \n",
    "                        \n",
    "\n",
    "                    elif len_udf>1:\n",
    "                        for udf in reversed(udf_splitter):\n",
    "                            if udf =='mul':\n",
    "                                query=multiplication_udf(final_columns,alias,final_df)\n",
    "                                query_list.append(query)\n",
    "                            elif udf=='sum':\n",
    "                                query= sum_initial_udf(columns,final_df,alias)\n",
    "                                #query_list.append(query)\n",
    "                                query= group_by_func(final_df,query_dict,grp_cols,alias,udf,final_columns)\n",
    "                                query_list.append(query)\n",
    "                            elif udf==\"coalesce\":\n",
    "                                query= coalesce_udf(columns,final_df,alias,final_columns,len_udf)\n",
    "                                query_list.append(query)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    columns =list_elements['base_col']\n",
    "                    alias=list_elements['Alias']\n",
    "                    if alias!='':\n",
    "                        query=final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                        query_list.append(query)\n",
    "        \n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "        else:\n",
    "            pass\n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not there\n",
    "\n",
    "def case_alias_getter(query1):\n",
    "    for column_dict in query1:\n",
    "        if type(column_dict)==dict:\n",
    "            if type(column_dict['value'])== dict:\n",
    "                for k,v in column_dict['value'].items():\n",
    "                    if k==\"case\":\n",
    "                        alias = column_dict['name']\n",
    "                        return alias\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be repaired\n",
    "def identifyCaseStatements():\n",
    "        regex = \"CASE(.*?)END\"\n",
    "        allCaseStatements=[]\n",
    "        matches = re.finditer(regex, query, re.IGNORECASE)\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            allCaseStatements.append(match.group())\n",
    "        return allCaseStatements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not there\n",
    "def case_or_clause(final_df,data):\n",
    "    signs =[\"=\"]\n",
    "    for sign in signs:\n",
    "        if sign in data:\n",
    "            if sign ==\"=\":\n",
    "                data_val=data.split(\"=\")[1]\n",
    "                data_col=data.split(\"=\")[0]\n",
    "                azeta= \"(\"+final_df+\"['\"+data_col+\"']==\"+data_val+\")\"\n",
    "            return azeta\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseStatementDetails(caseStatement):\n",
    "        whenSplits = caseStatement.lower().split(\"when\")[1:]\n",
    "        conditions = [whenSplit.split(\"then\")[0].strip() for whenSplit in whenSplits]\n",
    "        results = [whenSplit.split(\"then\")[1].split(\"else\")[0].strip() for whenSplit in whenSplits]\n",
    "        if \"else\" in caseStatement:\n",
    "            lastResult = caseStatement.split(\"else\")[1].split(\"end\")[0].strip()\n",
    "            results.append(lastResult)\n",
    "        else:\n",
    "            results[-1] = results[-1].split(\"end\")[0].strip()\n",
    "        return conditions, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not there\n",
    "\n",
    "def case_panda_builder(list_of_cols,query_selection,final_df): \n",
    "    panda_case_syntax=[]\n",
    "    for i in list_of_cols:\n",
    "        start = 'else'\n",
    "        end = 'end'\n",
    "        #final_df=\"df\"\n",
    "        else_cond= i[i.find(start)+len(start):i.rfind(end)]\n",
    "        final_else_part=''\n",
    "        if \"/\" in else_cond:\n",
    "            else_splitter=else_cond.split(\"/\")\n",
    "            div_part= final_df+\"['\"+else_splitter[0].strip()+\"']\"+\"/\"+final_df+\"['\"+else_splitter[-1].strip()+\"']\"\n",
    "            alias_assignment= case_alias_getter(query_selection)\n",
    "            #print(alias_assignment)\n",
    "            alias_assignment1 =final_df+\"['\"+alias_assignment+\"']\"\n",
    "            final_else_part=alias_assignment1+\"=\"+div_part\n",
    "        else:\n",
    "            pass\n",
    "        panda_case_syntax.append(final_else_part)\n",
    "        #print(final_else_part)\n",
    "    \n",
    "        conditions,results =caseStatementDetails(i)\n",
    "        then_clause = results[0]\n",
    "        #print(then_clause)\n",
    "        conditions_main=conditions[-1]\n",
    "        case1=\"\"\n",
    "        if \"or\" in conditions_main:\n",
    "            orSplitter = conditions_main.split(\" or \")\n",
    "            when_part=''\n",
    "            for cond in orSplitter:\n",
    "                abc = case_or_clause(final_df,cond)\n",
    "                when_part += abc+\"|\"\n",
    "            #print(\"-----this is when part------\")   \n",
    "            #print(when_part[:-1])\n",
    "            alias_assignment= case_alias_getter(query_selection)\n",
    "            case1=final_df+\".loc[\"+when_part[:-1]+\",\"+\"'\"+alias_assignment+\"']=\"+then_clause\n",
    "            #print((case1))\n",
    "            panda_case_syntax.append(case1)\n",
    "            #cases=cases.append(case1)\n",
    "            \n",
    "            \n",
    "        elif \"and\" in conditions_main:\n",
    "            andSplitter = conditions_main.split(\"and\")\n",
    "        else:\n",
    "            pass\n",
    "        #cases=cases.append(case1)\n",
    "    return panda_case_syntax\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not there\n",
    "def fomrat_udf_substr(select_list, final_df):\n",
    "    data_frame=[]\n",
    "    for column_dict in select_list:\n",
    "        if type(column_dict)==dict:\n",
    "            if type(column_dict['value'])== dict:\n",
    "                for k,v in column_dict['value'].items():\n",
    "                    if k==\"format\":\n",
    "                        alias = column_dict['name']\n",
    "                        values =v\n",
    "                        sliced_col= values[0]\n",
    "                        substr_val= values[-1]\n",
    "                        for k,v in substr_val.items(): # needs to be extended\n",
    "                            data_frame_str = final_df+\"['\"+alias+\"']=\"+final_df+\"['\"+sliced_col+\"'].str[:\"+str(v)+\"]\"\n",
    "                            data_frame.append(data_frame_str)\n",
    "                    \n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs main func starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query =\"\"\" SELECT a.* FROM AW_TGT_PROXY_DBO.IT_SCE8_POP_STD_RM_CAP_HIST AS a INNER JOIN ( select max( data_dt) AS maxdate \n",
    "# FROM AW_TGT_PROXY_DBO.IT_SCE8_POP_STD_RM_CAP_HIST) \n",
    "# AS b ON a.data_dt=b.maxdate WHERE a.set_status='ON'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"SELECT * ,marsha AS marsha2,FORMAT(stay_year, VARCHAR(7)) AS stay_year , marsha2 AS marsha , CASE WHEN co_rev_goal=' ' OR co_rev_goal=' ' OR co_rn_goal=0 OR co_rev_goal=0 THEN 0 ELSE co_rev_goal/co_rn_goal END AS co_rn_goal_adr, CASE WHEN def_otb=' ' OR def_rev=' ' OR def_otb=' ' OR def_rev=0 THEN 0 ELSE def_rev/def_otb END AS def_adr FROM Currents A JOIN Futures B ON A.marsha2 = B.marsha2 AND A.stay_year = B.stay_year\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"SELECT A.CHARTFIELD1, A.DEPTID, A.MI_SA_ID, A.OPERATING_UNIT, A.FISCAL_YEAR, A.ACCOUNTING_PERIOD, A.ACCOUNT, A.PRODUCT, A.BASE_CURRENCY, SUM( A.POSTED_TOTAL_AMT) AS SUM_A_POSTED_TOTAL_AMT_ FROM PS_MI_SA_LED_F00 A WHERE LEDGER = 'S_BUDAP' AND CHARTFIELD1 IN ( '16', '1L', '14', '1M', '60', '1B', '1F', 'BF', '09', '1H', '08', '1K', '29', '1B', '1B', '1Q', '1N', '2F', '29', '42', '1G', '1T', '84', '1D', '1R', '05', '1J', '1K', '1V', '19','20','21','26','27','31','33','34','39','43','47','56','57','58','61','64','65','68','73','93', '96','97') AND FISCAL_YEAR = YearC AND MI_SA_ID IN ( 'PR_ROOM_SALES') AND ( BASE_CURRENCY = CURRENCY_CD OR CURRENCY_CD = ' ') AND A.FISCAL_YEAR = year GROUP BY A.CHARTFIELD1, A.DEPTID, A.MI_SA_ID, A.OPERATING_UNIT, A.FISCAL_YEAR, A.ACCOUNTING_PERIOD, A.ACCOUNT, A.PRODUCT, A.BASE_CURRENCY ORDER BY A.CHARTFIELD1 ASC, A.ACCOUNTING_PERIOD DESC  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\" SELECT \n",
    " ACTUALS*-1 AS ACTUALS ,\n",
    " BUDGET*-1 AS BUDGET , \n",
    " SUBSTRING( _NAME_,2,2 ) AS a1 , \n",
    " CAST( name,int) AS monno\n",
    " FROM SLCT_SRVC_CATERING_TRANS  \n",
    " WHERE ACTUALS<>0 AND BUDGET<>0\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query =\"\"\"SELECT Marsha, TIMEF, REVPARINDEX as ca, REVPARINDEXLY, RICHG FROM DAYSTAR.master_final  \n",
    "# WHERE TIMEF in( 'L28','WE-28','WD-28','L28_G') AND MARSHA IN ( PropsList)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=\"\"\" SELECT b.year_cal , COUNT( b.date_dt) AS days_ytd_ly \n",
    "# FROM mrdw_dim_date b WHERE 100*b.year_cal+b.month_cal_id <= 201911-100 AND \n",
    "# 100*b.year_cal+b.month_cal_id >= 201911-112 GROUP BY b.year_cal ORDER BY b.year_cal \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=\"SELECT distinct prop_code, year( stay_dt) AS year, month( stay_dt) AS month, COUNT( user_capped) AS cap_ct FROM uat1_d GROUP BY prop_code, year, month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=\"\"\"SELECT distinct prop_code, year( stay_dt) AS year, month( stay_dt) AS month, COUNT( user_capped) AS act_ct FROM uat1_d WHERE act_status='Y' GROUP BY prop_code, year, month\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"SELECT sum(A.alpha) as alpha1, \n",
    "#     coalesce( A.crossover_rms,0) as CO_RN_Goal, \n",
    "#     coalesce( ( A.crossover_rms*B.crossover_gadr*-1),0) as CO_Rev_Goal,\n",
    "#     A.marsha as MARS, \n",
    "#     A.stay_year as stay_year_REN, \n",
    "#     A.CO_RN_Goal, \n",
    "#     A.CO_Rev_Goal, \n",
    "#     A.CO_RN_Goal_ADR, \n",
    "#     A.Def_OTB, \n",
    "#     A.Def_REV, \n",
    "#     A.Def_ADR, \n",
    "#     A.Target, \n",
    "#     A.Avg_Bkd  \n",
    "#     FROM merge_CrossOver1 A \n",
    "#     join merge_CrossOver B \n",
    "#     on A.marsha = B.marsha and A.marsha1 = B.marsha1\n",
    "#     join \n",
    "#     merge_CrossOver2 C on A.marsha = C.marsha and A.marsha1 = C.marsha1 \n",
    "#     Where A.Target=1 \n",
    "#     and A.Target in (1,2,3,4) \n",
    "#     and A.Avg_Bkd=\"ABCD\" \n",
    "# \tgroup by \n",
    "#     crossover_rms, \n",
    "# \tcrossover_gadr,marsha,\n",
    "# \tstay_year,\n",
    "# \tCO_RN_Goal,\n",
    "# \tCO_Rev_Goal,\n",
    "# \tCO_RN_Goal_ADR,\n",
    "# \tDef_OTB,\n",
    "# \tDef_REV,\n",
    "# \tDef_ADR,\n",
    "# \tTarget,\n",
    "# \tAvg_Bkd\n",
    "# \torder by \n",
    "#     A.marsha,A.Avg_Bkd\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=parse(query.lower())\n",
    "# a['orderby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query =\"\"\"SELECT \n",
    "#  ACTUALS*-1 AS ACTUALS ,\n",
    "#  BUDGET*-1 AS BUDGET , \n",
    "#  SUBSTRING(_NAME_,2,2) AS name ,\n",
    "#  CAST(name,int) as a1\n",
    "#  FROM SLCT_SRVC_CATERING_TRANS  \n",
    "#  WHERE ACTUALS<>0 AND BUDGET<>0\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_simple= query.lower()\n",
    "query_dict = parse(query.lower())\n",
    "select_list = query_dict[\"select\"]\n",
    "select_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"groupby\" in query_dict:\n",
    "    group_section = query_dict['groupby']\n",
    "    group_section\n",
    "else:\n",
    "    group_section=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dict = intermediate_select_dict(select_list)\n",
    "sql_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_agg= group_to_be_applied_on(sql_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = \"df_new\" \n",
    "grp_cols=grouped_columns(group_section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_queries=pandas_constructor(final_df,grp_cols,sql_dict,group_agg)\n",
    "for queries in panda_queries:\n",
    "    print(queries)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "format_udf=fomrat_udf_substr(select_list, final_df)\n",
    "for queries in format_udf:\n",
    "    print(queries)\n",
    "\n",
    "list_of_cols = identifyCaseStatements()\n",
    "list_of_cols\n",
    "abc=case_panda_builder(list_of_cols,select_list,final_df)\n",
    "for i in abc:\n",
    "    print(i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_udf(final_columns,alias,final_df):\n",
    "    print(final_columns)\n",
    "    print()\n",
    "    list_of_col = [\"row.\"+a for a in final_columns]\n",
    "    cols='*'.join(list_of_col)\n",
    "    query = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+'.apply(lambda row: '+cols+', axis = 1)'\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "list1=[0,\"A\",1,2,3]\n",
    "lister1 =[a for a in list1 if a!=0]\n",
    "print(lister1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_columns= ['actuals','a',\"b\"]\n",
    "alias=\"actuals\"\n",
    "final_df=\"df\"\n",
    "final_columns= ['actuals','aaa',-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-544303827072>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist_of_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"['\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"']\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinal_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-544303827072>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist_of_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"['\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"']\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinal_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "list_of_col = [final_df+\"['\"+a+\"']\" for a in final_columns]\n",
    "cols='*'.join(list_of_col)\n",
    "print(cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = [a for a in final_columns if type(a)==str]\n",
    "list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "cols='*'.join(list_of_col)\n",
    "print(cols)\n",
    "int_list = [str(a) for a in final_columns if type(a)==int or type(a)==float]\n",
    "cols1='*'.join(int_list)\n",
    "print(cols1)\n",
    "final = cols+\"*\"+cols1\n",
    "print(final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns= ['actuals','aaa',\"a\",-1]\n",
    "type_instance=all(isinstance(item, str) for item in final_columns)    \n",
    "if type_instance ==True:\n",
    "    str_list = [a for a in final_columns if type(a)==str]\n",
    "    list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "    final='*'.join(list_of_col)\n",
    "    result =final_df+\"['\"+alias+\"']=\"+final\n",
    "    print(result)\n",
    "    \n",
    "elif type_instance ==False:\n",
    "    str_list = [a for a in final_columns if type(a)==str]\n",
    "    list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "    cols='*'.join(list_of_col)\n",
    "    int_list = [str(a) for a in final_columns if type(a)==int or type(a)==float]\n",
    "    cols1='*'.join(int_list)\n",
    "    final = cols+\"*\"+cols1\n",
    "    result =final_df+\"['\"+alias+\"']=\"+final\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_udf(final_columns,final_df,alias):\n",
    "    type_instance=all(isinstance(item, str) for item in final_columns)    \n",
    "    if type_instance ==True:\n",
    "        str_list = [a for a in final_columns if type(a)==str]\n",
    "        list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "        final='*'.join(list_of_col)\n",
    "        result =final_df+\"['\"+alias+\"']=\"+final\n",
    "        return result\n",
    "    \n",
    "    elif type_instance ==False:\n",
    "        str_list = [a for a in final_columns if type(a)==str]\n",
    "        list_of_col = [final_df+\"['\"+a+\"']\" for a in str_list]\n",
    "        cols='*'.join(list_of_col)\n",
    "        int_list = [str(a) for a in final_columns if type(a)==int or type(a)==float]\n",
    "        cols1='*'.join(int_list)\n",
    "        final = cols+\"*\"+cols1\n",
    "        result =final_df+\"['\"+alias+\"']=\"+final\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplication_udf(final_columns,final_df,alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for list_elements in sql_dict:\n",
    "    columns = list_elements['base_col']\n",
    "    if columns!='*':\n",
    "        if columns!=[]:\n",
    "            final_columns =[s for s in columns if type(s)==str]\n",
    "            alias=list_elements['Alias']\n",
    "            udf=list_elements['udf']\n",
    "            udf_splitter = list_elements['udf'].split(',')\n",
    "            len_udf =len(udf_splitter)\n",
    "            \n",
    "            if len_udf>1:\n",
    "                for udf in reversed(udf_splitter):\n",
    "                    if udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_dict in select_list:\n",
    "    if type(column_dict)==dict:\n",
    "        if type(column_dict['value'])== dict:\n",
    "            for k,v in column_dict['value'].items():\n",
    "                if k==\"format\":\n",
    "                    alias = column_dict['name']\n",
    "                    print(alias)\n",
    "                    values =v\n",
    "                    sliced_col= values[0]\n",
    "                    print(sliced_col)\n",
    "                    substr_val= values[-1]\n",
    "                    for k,v in substr_val.items():\n",
    "                        print(v)\n",
    "                        dataFrame = \"d\"+\"  \"+str(v)+\"   \"+alias+\"    \"+sliced_col\n",
    "                        print(alpha)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fomrat_udf_substr(select_list, final_df):\n",
    "    for column_dict in select_list:\n",
    "        if type(column_dict)==dict:\n",
    "            if type(column_dict['value'])== dict:\n",
    "                for k,v in column_dict['value'].items():\n",
    "                    data_frame=\"\"\n",
    "                    if k==\"format\":\n",
    "                        alias = column_dict['name']\n",
    "                        values =v\n",
    "                        sliced_col= values[0]\n",
    "                        substr_val= values[-1]\n",
    "                        for k,v in substr_val.items():\n",
    "                            data_frame = final_df+\"['\"+alias+\"']=\"+final_df+\"['\"+sliced_col+\"'].str[:\"+str(v)+\"]\"\n",
    "                        return data_frame\n",
    "                    \n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomrat_udf_substr(select_list, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reader = pd.read_csv(\"C:/Users/arshashank/Desktop/27/SQLQueries_ETL.csv\")\n",
    "reader['alpha']=reader['SQL']\n",
    "for i in reader['alpha']:\n",
    "    print(i)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# reader['sql']\n",
    "# xlf = xlrd.open_workbook('C:/Users/arshashank/Desktop/27/SQLQueries_ETL.csv')\n",
    "# xls = xlf.sheet_by_name('SQLQueries_ETL')\n",
    "# data = xls.col_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[\"a\",-1]\n",
    "type(a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
