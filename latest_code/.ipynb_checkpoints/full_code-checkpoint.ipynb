{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moz_sql_parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(nested_json: dict, exclude: list=[''], sep: str='_') -> dict:\n",
    "    \"\"\"\n",
    "    Flatten a list of nested dicts.\n",
    "    \"\"\"\n",
    "    out = dict()\n",
    "    def flatten(x: (list, dict, str), name: str='', exclude=exclude):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                if a not in exclude:\n",
    "                    flatten(x[a], f'{name}{a}{sep}')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, f'{name}{i}{sep}')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(nested_json)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_details(select_list):\n",
    "    column_list = []\n",
    "    # Get column details    \n",
    "    if type(select_list) == str:\n",
    "        column_value = select_list\n",
    "        column_table = \"\"\n",
    "        alias=\"\"\n",
    "        collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "        column_list.append(collsttmp)\n",
    "        \n",
    "    elif type(select_list) == dict:\n",
    "        if type(select_list['value']) != dict:\n",
    "            if '.' in select_list['value']:\n",
    "                column_value = select_list['value'].split('.')[1]\n",
    "                column_table = select_list['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=select_list['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "                \n",
    "    elif type(select_list) == list:\n",
    "        for column_dict in select_list:\n",
    "            if type(column_dict['value']) !=dict:\n",
    "                if '.' in column_dict['value']:\n",
    "                    column_value = column_dict['value'].split('.')[1]\n",
    "                    column_table = column_dict['value'].split('.')[0]\n",
    "                    try:\n",
    "                        alias=column_dict['name']\n",
    "                    except:\n",
    "                        alias=\"\"\n",
    "                    collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                    column_list.append(collsttmp)\n",
    "                else:\n",
    "                    column_value = column_dict['value']\n",
    "                    column_table=\"\"\n",
    "                    try:\n",
    "                        alias=column_dict['name']\n",
    "                    except:\n",
    "                        alias=\"\"\n",
    "                    collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                    column_list.append(collsttmp)\n",
    "                    \n",
    "            else:\n",
    "                cols= list(flatten_json(column_dict['value']).values())\n",
    "                cols = [i for i in cols if type(i) !=int]\n",
    "                \n",
    "                for i in cols:\n",
    "                    if '.' in i:\n",
    "                        column_value = i.split('.')[1]\n",
    "                        column_table = i.split('.')[0]\n",
    "                        alias=\"\"                        \n",
    "                            \n",
    "                        collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                        column_list.append(collsttmp)\n",
    "                        \n",
    "                    else:\n",
    "                        column_value = i\n",
    "                        column_table=\"\"\n",
    "                        alias=\"\"\n",
    "\n",
    "                        collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                        column_list.append(collsttmp)            \n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_details(from_dict_list):\n",
    "\n",
    "    table_name=[]\n",
    "    join_list=[]\n",
    "    if type(from_dict_list) == str:\n",
    "        tbl=from_dict_list\n",
    "        alias=\"\"\n",
    "        tbltmp={\"Table\":tbl, \"Alias\":alias}\n",
    "        table_name.append(tbltmp)\n",
    "        \n",
    "    elif type(from_dict_list) == dict:\n",
    "        tbl=from_dict_list['value']\n",
    "        alias=from_dict_list['name']\n",
    "        tbltmp={\"Table\":tbl, \"Alias\":alias}\n",
    "        table_name.append(tbltmp)\n",
    "        \n",
    "    elif type(from_dict_list) == list:\n",
    "        for i in from_dict_list:\n",
    "            if 'value' in list(i.keys()):\n",
    "                #Means there is no join or first table\n",
    "                tbl=i['value']\n",
    "                try:\n",
    "                    alias=i['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                tbltmp={\"Table\":tbl, \"Alias\":alias}\n",
    "                table_name.append(tbltmp)\n",
    "                \n",
    "            elif 'join' in list(i.keys()):\n",
    "                #Means there is a join\n",
    "                keyjoinlist= [i for i in list(i.keys()) if 'join' in i]\n",
    "                JoinType=keyjoinlist[0]\n",
    "                tbl=i[JoinType]['value']\n",
    "                joincond=i['on']\n",
    "                try:\n",
    "                    alias=i[JoinType]['name']\n",
    "                except:\n",
    "                    alias=''\n",
    "                for k, v in joincond.items():\n",
    "                    if k =='and':\n",
    "                        for i in v:\n",
    "                            for key,val in i.items():\n",
    "                                eqtyp=key\n",
    "                                colleft=val[0]\n",
    "                                if \".\" in colleft:\n",
    "                                    colleftcol=val[0].split('.')[1]\n",
    "                                    collefttbl=val[0].split('.')[0]\n",
    "                                else:\n",
    "                                    colleftcol=val[0]\n",
    "                                    collefttbl=\"\"\n",
    "                                    \n",
    "                                colright=val[1]\n",
    "                                if \".\" in colright:\n",
    "                                    colrightcol=val[1].split('.')[1]\n",
    "                                    colrighttbl=val[1].split('.')[0]\n",
    "                                else:\n",
    "                                    colrightcol=val[1]\n",
    "                                    colrighttbl=\"\"\n",
    "                                joindict={\"EquationType\":eqtyp, \"LeftColumn\":colleftcol,\n",
    "                                          \"LeftTable\":collefttbl,\"RightColumn\":colrightcol,\n",
    "                                          \"RightTable\":colrighttbl, \"JoinType\":JoinType}\n",
    "                                join_list.append(joindict)\n",
    "                                \n",
    "                    elif k == \"eq\":\n",
    "                        eqtyp=k\n",
    "                        colleft=v[0]\n",
    "                        colright=v[1]\n",
    "                        if \".\" in colleft:\n",
    "                            colleftcol=v[0].split('.')[1]\n",
    "                            collefttbl=v[0].split('.')[0]\n",
    "                        else:\n",
    "                            colleftcol=v[0]\n",
    "                            collefttbl=\"\"\n",
    "                                    \n",
    "                        if \".\" in colright:\n",
    "                            colrightcol=v[1].split('.')[1]\n",
    "                            colrighttbl=v[1].split('.')[0]\n",
    "                        else:\n",
    "                            colrightcol=v[1]\n",
    "                            colrighttbl=\"\"\n",
    "                        joindict={\"EquationType\":eqtyp, \"LeftColumn\":colleftcol,\n",
    "                                          \"LeftTable\":collefttbl,\"RightColumn\":colrightcol,\n",
    "                                          \"RightTable\":colrighttbl, \"JoinType\":JoinType}\n",
    "                        join_list.append(joindict)\n",
    "                        \n",
    "                        \n",
    "                tbltmp={\"Table\":tbl, \"Alias\":alias}\n",
    "                table_name.append(tbltmp)\n",
    "                \n",
    "    return table_name, join_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_where_details(where_list):\n",
    "    wherelst=[]\n",
    "    for k,v in where_list.items():\n",
    "        if k =='and':\n",
    "            for i in v:\n",
    "                for key,val in i.items():\n",
    "                    eqtyp=key\n",
    "                    col=val[0]\n",
    "                    if \".\" in col:\n",
    "                        table=col.split(\".\")[0]\n",
    "                        col=col.split(\".\")[1]\n",
    "                    else:\n",
    "                        table=\"\"\n",
    "                        col=col\n",
    "                    condition=val[1]\n",
    "                    wheredict={\"EquationType\":eqtyp, \"Column\":col,\"Table\":table, \"Condition\":condition}\n",
    "                    wherelst.append(wheredict)\n",
    "        else:\n",
    "            eqtyp=k\n",
    "            col=v[0]\n",
    "            if \".\" in col:\n",
    "                table=col.split(\".\")[0]\n",
    "                col=col.split(\".\")[1]\n",
    "            else:\n",
    "                table=\"\"\n",
    "                col=col\n",
    "            condition=v[1]\n",
    "            wheredict={\"EquationType\":eqtyp, \"Column\":col,\"Table\":table, \"Condition\":condition}\n",
    "            wherelst.append(wheredict)\n",
    "    return wherelst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orderby_details(order_list):\n",
    "    order_dict=[]\n",
    "    for col in order_list:\n",
    "        if '.' in col['value']:\n",
    "            colname=col['value'].split('.')[1]\n",
    "            tblname=col['value'].split('.')[0]\n",
    "            orderdict={\"Column\":colname, \"Table\":tblname}\n",
    "            order_dict.append(orderdict)\n",
    "        else:\n",
    "            colname=col['value'].split('.')[1]\n",
    "            tblname=\"\"\n",
    "            orderdict={\"Column\":colname, \"Table\":tblname}\n",
    "            order_dict.append(orderdict)\n",
    "            \n",
    "    return order_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_builder_sql(table_name_list,join_list,col_list):\n",
    "    all=[]\n",
    "    Finaldf=''\n",
    "    for cols in join_list:\n",
    "        column_value=cols['LeftColumn']\n",
    "        column_table=cols['LeftTable']\n",
    "        alias=\"\"\n",
    "        collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "        col_list.append(collsttmp)\n",
    "        \n",
    "        column_value=cols['RightColumn']\n",
    "        column_table=cols['RightTable']\n",
    "        alias=\"\"\n",
    "        collsttmp={\"Column\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "        col_list.append(collsttmp)    \n",
    "        \n",
    "    for table_name in table_name_list:\n",
    "        #Reset Column Rename List for different table\n",
    "        col_rename_dict={}\n",
    "        querycols=''\n",
    "\n",
    "        for columns in col_list:\n",
    "            \n",
    "            #Querycolumnsonly\n",
    "            if columns['Table'].upper() == table_name['Table'].upper() or columns['Table'].upper() == table_name['Alias'].upper():\n",
    "                querycols=querycols+','+columns['Column'] \n",
    "            elif len(columns['Table']) ==0:\n",
    "                querycols=querycols+','+columns['Column'] \n",
    "            #Column Renaming \n",
    "            if len(columns['Alias']) > 0:\n",
    "                \n",
    "                if columns['Table'].upper() == table_name['Table'].upper() or columns['Table'].upper() == table_name['Alias'].upper():\n",
    "                    if columns['Column'] not in col_rename_dict.keys():\n",
    "                        col_rename_dict[columns['Column']] = columns['Alias']\n",
    "                                            \n",
    "                elif len(columns['Table']) ==0:\n",
    "                    if columns['Column'] not in col_rename_dict.keys():\n",
    "                        col_rename_dict[columns['Column']] = columns['Alias']\n",
    "                        \n",
    "                        \n",
    "        # 1. create connection to required database e.g. snowflake to read table\n",
    "        querycols=querycols.strip(',')\n",
    "        if len(querycols) > 0:\n",
    "            sql = f\"select {querycols} from {table_name['Table']}\"\n",
    "        else:\n",
    "            sql = f\"select * from {table_name['Table']}\"\n",
    "           \n",
    "        \n",
    "        # create where list\n",
    "        if \"where\" in query_dict.keys():\n",
    "            where_list = query_dict[\"where\"]\n",
    "            where_clauses = get_where_details(where_list)\n",
    "            whereclausecntr=0\n",
    "            # add where clause to table query  \n",
    "            for where in where_clauses:\n",
    "                whereclausecntr+=1\n",
    "            \n",
    "                if type(where['Condition']) == str:\n",
    "                    wherecondtn = \"\\\"{0}\\\"\".format(where['Condition'])\n",
    "                elif type(where['Condition']) == list:\n",
    "                    wherecondtn = tuple(i for i in where['Condition'])\n",
    "                else:\n",
    "                    wherecondtn = where['Condition']                             \n",
    "                                    \n",
    "                \n",
    "                if where['Table'].upper() == table_name['Table'].upper() or where['Table'].upper() == table_name['Alias'].upper():\n",
    "                    if where['EquationType'] =='eq':\n",
    "                    \n",
    "                        if whereclausecntr ==1:\n",
    "                            sql = sql+ \" where {0}={1}\".format(where['Column'],wherecondtn)\n",
    "                        else:\n",
    "                            sql = sql+ \" and {0}={1}\".format(where['Column'],wherecondtn)\n",
    "                    if where['EquationType'] =='in':\n",
    "                    \n",
    "                        if whereclausecntr ==1:\n",
    "                            sql = sql+ \" where {0} in {1}\".format(where['Column'],wherecondtn)\n",
    "                        else:\n",
    "                            sql = sql+ \" and {0} in {1}\".format(where['Column'],wherecondtn)\n",
    "            \n",
    "                elif len(where['Table']) ==0:\n",
    "                    if where['EquationType'] =='eq':\n",
    "                    \n",
    "                        if whereclausecntr ==1:\n",
    "                            sql = sql+ \" where {0}={1}\".format(where['Column'],wherecondtn )\n",
    "                        else:\n",
    "                            sql = sql+ \" and {0}={1}\".format(where['Column'],wherecondtn )\n",
    "                    if where['EquationType'] =='in':\n",
    "                    \n",
    "                        if whereclausecntr ==1:\n",
    "                            sql = sql+ \" where {0} in {1}\".format(where['Column'],wherecondtn)\n",
    "                        else:\n",
    "                            sql = sql+ \" and {0} in {1}\".format(where['Column'],wherecondtn)\n",
    "                        \n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        defineDF = table_name['Table']+\"_df\" + \" = \" + \"pd.read_sql('\" + sql + \"')\"\n",
    "        all.append(defineDF)\n",
    "        if col_rename_dict:\n",
    "            alpha1 = f\"{table_name['Table']}_df={table_name['Table']}_df.rename(columns={col_rename_dict})\"\n",
    "            all.append(alpha1)\n",
    "        else:\n",
    "            alpha1 = f\"{table_name['Table']}_df={table_name['Table']}_df\"\n",
    "            all.append(alpha1)\n",
    "            \n",
    "        \n",
    "    #print(\"________(first function)________\")                  \n",
    "    #Add Join Conditions\n",
    "    Lefttablelist=[]\n",
    "    left_on=[]\n",
    "    right_on=[]\n",
    "    loopcntr=0\n",
    "    mergecntr=0\n",
    "    mergedfname=''\n",
    "    for joins in join_list:\n",
    "        loopcntr+=1\n",
    "        Lefttable=[i['Table'] for i in table_name_list if i['Table'].upper() == joins['LeftTable'].upper() \n",
    "                    or i['Alias'].upper() == joins['LeftTable'].upper()][0]\n",
    "        \n",
    "        Righttable=[i['Table'] for i in table_name_list if i['Table'].upper() == joins['RightTable'].upper() \n",
    "                    or i['Alias'].upper() == joins['RightTable'].upper()][0]\n",
    "        \n",
    "        Leftjoincol=joins['LeftColumn']\n",
    "        Rightjoincol=joins['RightColumn']\n",
    "                  \n",
    "        \n",
    "        if 'join' == joins['JoinType'] or 'inner' in joins['JoinType']:\n",
    "            how='inner'\n",
    "        elif 'left' in joins['JoinType']:\n",
    "            how='left'\n",
    "        elif 'right' in joins['JoinType']:\n",
    "            how='right'\n",
    "            \n",
    "        Bothtable=Lefttable+\"#\"+Righttable\n",
    "        if len(Lefttablelist) ==0:\n",
    "            left_on.append(Leftjoincol)\n",
    "            right_on.append(Rightjoincol)\n",
    "            Lefttablelist.append(Bothtable)\n",
    "            Lefttablelist=list(set(Lefttablelist))\n",
    "            alpha2 = \"\"\"{0} =pd.merge({1},{2},how={3},left_on={4},right_on ={4} )\"\"\".format(Lefttablelist[-1].split('#')[0]+'_'+Lefttablelist[-1].split('#')[1]+'_df',Lefttablelist[-1].split('#')[0]+'_df',Lefttablelist[-1].split('#')[1]+'_df',how, left_on, right_on )\n",
    "            all.append(alpha2)\n",
    "                  \n",
    "            mergedfname=Lefttablelist[-1].split('#')[0]+'_'+Lefttablelist[-1].split('#')[1]\n",
    "            print(type(mergedfname))\n",
    "\n",
    "        elif Bothtable == Lefttablelist[-1] and loopcntr < len(join_list):\n",
    "            left_on.append(Leftjoincol)\n",
    "            right_on.append(Rightjoincol)\n",
    "            Lefttablelist.append(Bothtable)\n",
    "            Lefttablelist=list(set(Lefttablelist))\n",
    "            \n",
    "            \n",
    "        elif Bothtable != Lefttablelist[-1] and loopcntr < len(join_list):\n",
    "            mergecntr+=1\n",
    "            if mergecntr ==1:\n",
    "                alpha2 = \"\"\"{0} =pd.merge({1},{2},how={3},left_on={4},right_on ={4} )\"\"\".format(Lefttablelist[-1].split('#')[0]+'_'+Lefttablelist[-1].split('#')[1]+'_df',Lefttablelist[-1].split('#')[0]+'_df',Lefttablelist[-1].split('#')[1]+'_df',how, left_on, right_on )\n",
    "                all.append(alpha2)\n",
    "                mergedfname=Lefttablelist[-1].split('#')[0]+'_'+Lefttablelist[-1].split('#')[1]\n",
    "            else:\n",
    "                mergedfname=mergedfname+'_'+Lefttablelist[-1].split('#')[1]\n",
    "                alpha2 = \"\"\"{0} =pd.merge({1},{2},how={3},left_on={4},right_on ={4} )\"\"\".format(mergedfname,mergedfname,Lefttablelist[-1].split('#')[1]+'_df', how, left_on, right_on)\n",
    "                all.append(alpha2)\n",
    "                  \n",
    "            all.append(mergedfname)\n",
    "            Lefttablelist=[]\n",
    "            Lefttablelist.append(Bothtable)\n",
    "            Lefttablelist=list(set(Lefttablelist))\n",
    "            left_on=[]\n",
    "            left_on.append(Leftjoincol)\n",
    "            right_on=[]\n",
    "            right_on.append(Rightjoincol)\n",
    "            \n",
    "        else:\n",
    "            left_on.append(Leftjoincol)\n",
    "            right_on.append(Rightjoincol)\n",
    "            alpha2= \"\"\"{0} =pd.merge({1},{2},how={3},left_on={4},right_on ={4} )\"\"\".format(mergedfname+'_'+Righttable+'_df',mergedfname+'_df',Righttable,how, left_on, right_on )\n",
    "            all.append(alpha2)\n",
    "            mergedfname=mergedfname+'_'+Righttable\n",
    "            all.append(mergedfname)       \n",
    "            \n",
    "    Finaldf=mergedfname+'_df'\n",
    "#     print(\"Final Dataframe is:\",Finaldf)\n",
    "    \n",
    "    #logger\n",
    "    deletePart = \"{0} = {0}.loc[:,~{0}.columns.duplicated()]\".format(Finaldf)\n",
    "    all.append(deletePart)\n",
    "                  \n",
    "    #Order By Cluases\n",
    "    if \"orderby\" in query_dict:\n",
    "        order_list=query_dict[\"orderby\"]\n",
    "        order_dict=get_orderby_details(order_list)\n",
    "        order_list_fnl=[]\n",
    "        for i in order_dict:\n",
    "            order_list_fnl.append(i['Column'])\n",
    "        order_by = \"{0}.sort_values(by={1})\".format(Finaldf,order_list_fnl)\n",
    "        all.append(order_by)\n",
    "    else:\n",
    "        pass\n",
    "    return all,Finaldf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_complex(select_list):\n",
    "    column_list = []\n",
    "    for column_dict in select_list:\n",
    "        if type(column_dict['value'])== str:\n",
    "            if '.' in column_dict['value']:\n",
    "                column_value = column_dict['value'].split('.')[1]\n",
    "                column_table = column_dict['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"base_col\":column_value,\"udf\":\"\",\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "            else:\n",
    "                column_value = column_dict['value']\n",
    "                column_table=\"\"\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"base_col\":column_value,\"udf\":\"\",\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "            \n",
    "            \n",
    "        elif type(column_dict['value'])== dict:\n",
    "            if '.' in column_dict['value']:\n",
    "                column_value = column_dict['value'].split('.')[1]\n",
    "                column_table = column_dict['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                colsttmp={\"base_col\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                column_list.append(colsttmp)\n",
    "            else:\n",
    "                column_value=column_dict['value']\n",
    "                final_col=[]\n",
    "                for k,v in column_dict['value'].items():\n",
    "                    udf=k\n",
    "                    cols=v\n",
    "                    if type(cols)==str:\n",
    "                        if '.' in cols:\n",
    "                            col_name =cols.split('.')\n",
    "                            final_col.append(col_name[1])\n",
    "                        else:\n",
    "                            final_col.append(cols)\n",
    "                    else:\n",
    "                        for i in cols:\n",
    "                            if type(i)==str:\n",
    "                                if '.' in i:\n",
    "                                    column_name= i.split('.')\n",
    "                                    col_name= column_name[1]\n",
    "                                    final_col.append(col_name)\n",
    "                                else:\n",
    "                                    final_col.append(i)\n",
    "                        \n",
    "                            elif type(i)==int:\n",
    "                                final_col.append(i)\n",
    "                    \n",
    "                            elif type(i)==dict:\n",
    "                                new_dict=i\n",
    "                                for k,v in new_dict.items():\n",
    "                                    extra_udf=k\n",
    "                                    udf=udf+\",\"+extra_udf\n",
    "                                    cols=v\n",
    "                                    for i in cols:\n",
    "                                        if '.' in i:\n",
    "                                            splitter= i.split('.')\n",
    "                                            part1=splitter[0] \n",
    "                                            part2=splitter[1]\n",
    "                                            final_col.append(part2)\n",
    "                                        else:\n",
    "                                            final_col.append(i)    \n",
    "                            else:\n",
    "                                pass\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                colltmp={\"base_col\":final_col, \"udf\":udf,\"Alias\":alias}\n",
    "                column_list.append(colltmp)\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def panda_builder(final_df,sql_dict):\n",
    "    query_list=[]\n",
    "    for list_elements in sql_dict:\n",
    "        columns =list_elements['base_col']\n",
    "        final_columns =[s for s in columns if type(s)==str]\n",
    "        alias=list_elements['Alias']\n",
    "        udf=list_elements['udf']\n",
    "        if list_elements['udf']!='':\n",
    "            udf_splitter = list_elements['udf'].split(',')\n",
    "            len_udf =len(udf_splitter)\n",
    "            if  len_udf==1 and udf==\"coalesce\":\n",
    "                coalesce_filler=str(columns[-1])\n",
    "                query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".\"+final_columns[0]+\".fillna(value=\"+coalesce_filler+',inplace=True)'\n",
    "                query_list.append(query)\n",
    "            elif len_udf==1 and udf==\"mul\":\n",
    "                list_of_col = [\"row.\"+a for a in final_columns]\n",
    "                cols='*'.join(list_of_col)\n",
    "                query = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+'.apply(lambda row: '+cols+', axis = 1)'\n",
    "                query_list.append(query)\n",
    "                \n",
    "            # THIS PART NEEDS TO BE REVISITED\n",
    "            elif len_udf==1 and udf==\"sum\":\n",
    "                columns=columns[0]\n",
    "                query= final_df+\"[`\"+columns+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                query_list.append(query)\n",
    "            \n",
    "            elif len_udf>1:\n",
    "                # here we need to consider a scenario where the udf is not more than2 udfs\n",
    "                for udf in reversed(udf_splitter):\n",
    "                    if udf =='mul':\n",
    "                        list_of_col = [\"row.\"+a for a in final_columns]\n",
    "                        cols='*'.join(list_of_col)\n",
    "                        query = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+'.apply(lambda row: '+cols+', axis = 1)'\n",
    "                        query_list.append(query)\n",
    "                    elif udf=='coalesce':\n",
    "                        coalesce_filler=str(columns[-1])\n",
    "                        query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".\"+final_columns[0]+\".fillna(value=\"+coalesce_filler+',inplace=True)'\n",
    "                        query_list.append(query) \n",
    "                    \n",
    "                    \n",
    "        else:\n",
    "            columns =list_elements['base_col']\n",
    "            alias=list_elements['Alias']\n",
    "            if alias=='':\n",
    "                query=final_df+\"[`\"+columns+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                query_list.append(query)\n",
    "            else:\n",
    "                query=final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                query_list.append(query)\n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grp_cols(group_section):\n",
    "    list1=[]\n",
    "    for i in group_section:\n",
    "        values =i['value']\n",
    "        list1.append(values)\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_agg(select_list):\n",
    "    for i in select_list:\n",
    "        if i['udf']==\"sum\":\n",
    "            return i['base_col']\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_func(final_df,query_dict,grp_cols,group_agg):\n",
    "    if 'groupby' in query_dict.keys():\n",
    "        abc = final_df+\"=\"+final_df+\".groupby(\"+str(grp_cols)+\")\"+str(group_agg)+\".agg(sum)\"\n",
    "    return abc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT sum(A.alpha) as alpha1, \n",
    "    coalesce( A.crossover_rms,0) as CO_RN_Goal, \n",
    "    coalesce( ( A.crossover_rms*B.crossover_gadr),0) as CO_Rev_Goal,\n",
    "    A.marsha as MARS, \n",
    "    A.stay_year as stay_year_REN, \n",
    "    A.CO_RN_Goal, \n",
    "    A.CO_Rev_Goal, \n",
    "    A.CO_RN_Goal_ADR, \n",
    "    A.Def_OTB, \n",
    "    A.Def_REV, \n",
    "    A.Def_ADR, \n",
    "    A.Target, \n",
    "    A.Avg_Bkd  \n",
    "    FROM merge_CrossOver1 A \n",
    "    join merge_CrossOver B \n",
    "    on A.marsha = B.marsha and A.marsha1 = B.marsha1\n",
    "    join \n",
    "    merge_CrossOver2 C on A.marsha = C.marsha and A.marsha1 = C.marsha1 \n",
    "    Where A.Target=1 \n",
    "    and A.Target in (1,2,3,4) \n",
    "    and A.Avg_Bkd=\"ABCD\" \n",
    "\tgroup by \n",
    "    crossover_rms, \n",
    "\tcrossover_gadr,marsha,\n",
    "\tstay_year,\n",
    "\tCO_RN_Goal,\n",
    "\tCO_Rev_Goal,\n",
    "\tCO_RN_Goal_ADR,\n",
    "\tDef_OTB,\n",
    "\tDef_REV,\n",
    "\tDef_ADR,\n",
    "\tTarget,\n",
    "\tAvg_Bkd\n",
    "\torder by \n",
    "    A.marsha,A.Avg_Bkd\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = parse(query.lower())\n",
    "select_list = query_dict[\"select\"]\n",
    "group_section = query_dict['groupby']\n",
    "from_tag = query_dict[\"from\"]\n",
    "col_list = get_column_details(select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['merge_crossover1_df = pd.read_sql(\\'select alpha,crossover_rms,crossover_rms,marsha,stay_year,co_rn_goal,co_rev_goal,co_rn_goal_adr,def_otb,def_rev,def_adr,target,avg_bkd,marsha,marsha1,marsha,marsha1 from merge_crossover1 where target=1 and target in (1, 2, 3, 4) and avg_bkd=\"abcd\"\\')', \"merge_crossover1_df=merge_crossover1_df.rename(columns={'marsha': 'mars', 'stay_year': 'stay_year_ren'})\", \"merge_crossover_df = pd.read_sql('select crossover_gadr,marsha,marsha1 from merge_crossover')\", 'merge_crossover_df=merge_crossover_df', \"merge_crossover2_df = pd.read_sql('select marsha,marsha1 from merge_crossover2')\", 'merge_crossover2_df=merge_crossover2_df', \"merge_crossover1_merge_crossover_df =pd.merge(merge_crossover1_df,merge_crossover_df,how=inner,left_on=['marsha'],right_on =['marsha'] )\", \"merge_crossover1_merge_crossover_df =pd.merge(merge_crossover1_df,merge_crossover_df,how=inner,left_on=['marsha', 'marsha1'],right_on =['marsha', 'marsha1'] )\", 'merge_crossover1_merge_crossover', \"merge_crossover1_merge_crossover_merge_crossover2_df =pd.merge(merge_crossover1_merge_crossover_df,merge_crossover2,how=inner,left_on=['marsha', 'marsha1'],right_on =['marsha', 'marsha1'] )\", 'merge_crossover1_merge_crossover_merge_crossover2', 'merge_crossover1_merge_crossover_merge_crossover2_df = merge_crossover1_merge_crossover_merge_crossover2_df.loc[:,~merge_crossover1_merge_crossover_merge_crossover2_df.columns.duplicated()]', \"merge_crossover1_merge_crossover_merge_crossover2_df.sort_values(by=['marsha', 'avg_bkd'])\"]\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df\n"
     ]
    }
   ],
   "source": [
    "table_name_list,join_list = get_table_details(from_tag)\n",
    "after_from = pandas_builder_sql(table_name_list,join_list,col_list)\n",
    "after_from_df=after_from[0]\n",
    "final_dataframe = after_from[-1]\n",
    "\n",
    "print((after_from_df))\n",
    "print(final_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_crossover1_df = pd.read_sql('select alpha,crossover_rms,crossover_rms,marsha,stay_year,co_rn_goal,co_rev_goal,co_rn_goal_adr,def_otb,def_rev,def_adr,target,avg_bkd,marsha,marsha1,marsha,marsha1 from merge_crossover1 where target=1 and target in (1, 2, 3, 4) and avg_bkd=\"abcd\"')\n",
      "\n",
      "\n",
      "merge_crossover1_df=merge_crossover1_df.rename(columns={'marsha': 'mars', 'stay_year': 'stay_year_ren'})\n",
      "\n",
      "\n",
      "merge_crossover_df = pd.read_sql('select crossover_gadr,marsha,marsha1 from merge_crossover')\n",
      "\n",
      "\n",
      "merge_crossover_df=merge_crossover_df\n",
      "\n",
      "\n",
      "merge_crossover2_df = pd.read_sql('select marsha,marsha1 from merge_crossover2')\n",
      "\n",
      "\n",
      "merge_crossover2_df=merge_crossover2_df\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_df =pd.merge(merge_crossover1_df,merge_crossover_df,how=inner,left_on=['marsha'],right_on =['marsha'] )\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_df =pd.merge(merge_crossover1_df,merge_crossover_df,how=inner,left_on=['marsha', 'marsha1'],right_on =['marsha', 'marsha1'] )\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df =pd.merge(merge_crossover1_merge_crossover_df,merge_crossover2,how=inner,left_on=['marsha', 'marsha1'],right_on =['marsha', 'marsha1'] )\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df = merge_crossover1_merge_crossover_merge_crossover2_df.loc[:,~merge_crossover1_merge_crossover_merge_crossover2_df.columns.duplicated()]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df.sort_values(by=['marsha', 'avg_bkd'])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in after_from_df:\n",
    "    print(i)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_crossover1_merge_crossover_merge_crossover2_df[`alpha`]=merge_crossover1_merge_crossover_merge_crossover2_df[`alpha`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df.crossover_rms.fillna(value=0,inplace=True)\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df.apply(lambda row: row.crossover_rms*row.crossover_gadr, axis = 1)\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df.crossover_rms.fillna(value=0,inplace=True)\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`mars`]=merge_crossover1_merge_crossover_merge_crossover2_df[`marsha`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`stay_year_ren`]=merge_crossover1_merge_crossover_merge_crossover2_df[`stay_year`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal_adr`]=merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal_adr`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`def_otb`]=merge_crossover1_merge_crossover_merge_crossover2_df[`def_otb`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`def_rev`]=merge_crossover1_merge_crossover_merge_crossover2_df[`def_rev`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`def_adr`]=merge_crossover1_merge_crossover_merge_crossover2_df[`def_adr`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`target`]=merge_crossover1_merge_crossover_merge_crossover2_df[`target`]\n",
      "\n",
      "\n",
      "merge_crossover1_merge_crossover_merge_crossover2_df[`avg_bkd`]=merge_crossover1_merge_crossover_merge_crossover2_df[`avg_bkd`]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df= final_dataframe\n",
    "sql_dict = select_complex(select_list)\n",
    "pandas_output=panda_builder(final_df,sql_dict)\n",
    "for i in pandas_output:\n",
    "    print(i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"merge_crossover1_merge_crossover_merge_crossover2_df=merge_crossover1_merge_crossover_merge_crossover2_df.groupby(['crossover_rms', 'crossover_gadr', 'marsha', 'stay_year', 'co_rn_goal', 'co_rev_goal', 'co_rn_goal_adr', 'def_otb', 'def_rev', 'def_adr', 'target', 'avg_bkd'])['alpha'].agg(sum)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_cols=grp_cols(group_section)\n",
    "group_agg=group_agg(select_complex(select_list))\n",
    "group_by_func(final_df,query_dict,grp_cols,group_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
