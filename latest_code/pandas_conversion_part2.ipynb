{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas conversion from SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moz_sql_parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': 'crossover_rms'},\n",
       " {'value': 'crossover_gadr'},\n",
       " {'value': 'marsha'},\n",
       " {'value': 'stay_year'},\n",
       " {'value': 'co_rn_goal'},\n",
       " {'value': 'co_rev_goal'},\n",
       " {'value': 'co_rn_goal_adr'},\n",
       " {'value': 'def_otb'},\n",
       " {'value': 'def_rev'},\n",
       " {'value': 'def_adr'},\n",
       " {'value': 'target'},\n",
       " {'value': 'avg_bkd'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"SELECT sum(A.alpha) as alpha1, \n",
    "    coalesce( A.crossover_rms,0) as CO_RN_Goal, \n",
    "    coalesce( ( A.crossover_rms*B.crossover_gadr),0) as CO_Rev_Goal,\n",
    "    A.marsha as MARS, \n",
    "    A.stay_year as stay_year_REN, \n",
    "    A.CO_RN_Goal, \n",
    "    A.CO_Rev_Goal, \n",
    "    A.CO_RN_Goal_ADR, \n",
    "    A.Def_OTB, \n",
    "    A.Def_REV, \n",
    "    A.Def_ADR, \n",
    "    A.Target, \n",
    "    A.Avg_Bkd  \n",
    "    FROM merge_CrossOver1 A \n",
    "    join merge_CrossOver B \n",
    "    on A.marsha = B.marsha and A.marsha1 = B.marsha1\n",
    "    join \n",
    "    merge_CrossOver2 C on A.marsha = C.marsha and A.marsha1 = C.marsha1 \n",
    "    Where A.Target=1 \n",
    "    and A.Target in (1,2,3,4) \n",
    "    and A.Avg_Bkd=\"ABCD\" \n",
    "\tgroup by \n",
    "    crossover_rms, \n",
    "\tcrossover_gadr,marsha,\n",
    "\tstay_year,\n",
    "\tCO_RN_Goal,\n",
    "\tCO_Rev_Goal,\n",
    "\tCO_RN_Goal_ADR,\n",
    "\tDef_OTB,\n",
    "\tDef_REV,\n",
    "\tDef_ADR,\n",
    "\tTarget,\n",
    "\tAvg_Bkd\n",
    "\torder by \n",
    "    A.marsha,A.Avg_Bkd\"\"\"\n",
    "query_dict = parse(query.lower())\n",
    "query_dict\n",
    "select_list = query_dict[\"select\"]\n",
    "select_list\n",
    "group_section = query_dict['groupby']\n",
    "group_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': [{'value': {'sum': 'a.alpha'}, 'name': 'alpha1'},\n",
       "  {'value': {'coalesce': ['a.crossover_rms', 0]}, 'name': 'co_rn_goal'},\n",
       "  {'value': {'coalesce': [{'mul': ['a.crossover_rms', 'b.crossover_gadr']},\n",
       "     0]},\n",
       "   'name': 'co_rev_goal'},\n",
       "  {'value': 'a.marsha', 'name': 'mars'},\n",
       "  {'value': 'a.stay_year', 'name': 'stay_year_ren'},\n",
       "  {'value': 'a.co_rn_goal'},\n",
       "  {'value': 'a.co_rev_goal'},\n",
       "  {'value': 'a.co_rn_goal_adr'},\n",
       "  {'value': 'a.def_otb'},\n",
       "  {'value': 'a.def_rev'},\n",
       "  {'value': 'a.def_adr'},\n",
       "  {'value': 'a.target'},\n",
       "  {'value': 'a.avg_bkd'}],\n",
       " 'from': [{'value': 'merge_crossover1', 'name': 'a'},\n",
       "  {'join': {'name': 'b', 'value': 'merge_crossover'},\n",
       "   'on': {'and': [{'eq': ['a.marsha', 'b.marsha']},\n",
       "     {'eq': ['a.marsha1', 'b.marsha1']}]}},\n",
       "  {'join': {'name': 'c', 'value': 'merge_crossover2'},\n",
       "   'on': {'and': [{'eq': ['a.marsha', 'c.marsha']},\n",
       "     {'eq': ['a.marsha1', 'c.marsha1']}]}}],\n",
       " 'where': {'and': [{'eq': ['a.target', 1]},\n",
       "   {'in': ['a.target', [1, 2, 3, 4]]},\n",
       "   {'eq': ['a.avg_bkd', 'abcd']}]},\n",
       " 'groupby': [{'value': 'crossover_rms'},\n",
       "  {'value': 'crossover_gadr'},\n",
       "  {'value': 'marsha'},\n",
       "  {'value': 'stay_year'},\n",
       "  {'value': 'co_rn_goal'},\n",
       "  {'value': 'co_rev_goal'},\n",
       "  {'value': 'co_rn_goal_adr'},\n",
       "  {'value': 'def_otb'},\n",
       "  {'value': 'def_rev'},\n",
       "  {'value': 'def_adr'},\n",
       "  {'value': 'target'},\n",
       "  {'value': 'avg_bkd'}],\n",
       " 'orderby': [{'value': 'a.marsha'}, {'value': 'a.avg_bkd'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate step which seperates the UDF'S , original cols and its associated aliases if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_complex(select_list):\n",
    "    column_list = []\n",
    "    for column_dict in select_list:\n",
    "        if type(column_dict['value'])== str:\n",
    "            if '.' in column_dict['value']:\n",
    "                column_value = column_dict['value'].split('.')[1]\n",
    "                column_table = column_dict['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"base_col\":column_value,\"udf\":\"\",\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "            else:\n",
    "                column_value = column_dict['value']\n",
    "                column_table=\"\"\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                collsttmp={\"base_col\":column_value,\"udf\":\"\",\"Alias\":alias}\n",
    "                column_list.append(collsttmp)\n",
    "            \n",
    "            \n",
    "        elif type(column_dict['value'])== dict:\n",
    "            if '.' in column_dict['value']:\n",
    "                column_value = column_dict['value'].split('.')[1]\n",
    "                column_table = column_dict['value'].split('.')[0]\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                colsttmp={\"base_col\":column_value, \"Table\":column_table,\"Alias\":alias}\n",
    "                column_list.append(colsttmp)\n",
    "            else:\n",
    "                column_value=column_dict['value']\n",
    "                final_col=[]\n",
    "                for k,v in column_dict['value'].items():\n",
    "                    udf=k\n",
    "                    cols=v\n",
    "                    if type(cols)==str:\n",
    "                        if '.' in cols:\n",
    "                            col_name =cols.split('.')\n",
    "                            final_col.append(col_name[1])\n",
    "                        else:\n",
    "                            final_col.append(cols)\n",
    "                    else:\n",
    "                        for i in cols:\n",
    "                            if type(i)==str:\n",
    "                                if '.' in i:\n",
    "                                    column_name= i.split('.')\n",
    "                                    col_name= column_name[1]\n",
    "                                    final_col.append(col_name)\n",
    "                                else:\n",
    "                                    final_col.append(i)\n",
    "                        \n",
    "                            elif type(i)==int:\n",
    "                                final_col.append(i)\n",
    "                    \n",
    "                            elif type(i)==dict:\n",
    "                                new_dict=i\n",
    "                                for k,v in new_dict.items():\n",
    "                                    extra_udf=k\n",
    "                                    udf=udf+\",\"+extra_udf\n",
    "                                    cols=v\n",
    "                                    for i in cols:\n",
    "                                        if '.' in i:\n",
    "                                            splitter= i.split('.')\n",
    "                                            part1=splitter[0] \n",
    "                                            part2=splitter[1]\n",
    "                                            final_col.append(part2)\n",
    "                                        else:\n",
    "                                            final_col.append(i)    \n",
    "                            else:\n",
    "                                pass\n",
    "                try:\n",
    "                    alias=column_dict['name']\n",
    "                except:\n",
    "                    alias=\"\"\n",
    "                colltmp={\"base_col\":final_col, \"udf\":udf,\"Alias\":alias}\n",
    "                column_list.append(colltmp)\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'base_col': ['alpha'], 'udf': 'sum', 'Alias': 'alpha1'},\n",
       " {'base_col': ['crossover_rms', 0], 'udf': 'coalesce', 'Alias': 'co_rn_goal'},\n",
       " {'base_col': ['crossover_rms', 'crossover_gadr', 0],\n",
       "  'udf': 'coalesce,mul',\n",
       "  'Alias': 'co_rev_goal'},\n",
       " {'base_col': 'marsha', 'udf': '', 'Alias': 'mars'},\n",
       " {'base_col': 'stay_year', 'udf': '', 'Alias': 'stay_year_ren'},\n",
       " {'base_col': 'co_rn_goal', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'co_rev_goal', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'co_rn_goal_adr', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'def_otb', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'def_rev', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'def_adr', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'target', 'udf': '', 'Alias': ''},\n",
       " {'base_col': 'avg_bkd', 'udf': '', 'Alias': ''}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_complex(select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This step will return the panda code of select part of the query in step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def panda_builder(final_df,sql_dict):\n",
    "    query_list=[]\n",
    "    for list_elements in sql_dict:\n",
    "        columns =list_elements['base_col']\n",
    "        final_columns =[s for s in columns if type(s)==str]\n",
    "        alias=list_elements['Alias']\n",
    "        udf=list_elements['udf']\n",
    "        if list_elements['udf']!='':\n",
    "            udf_splitter = list_elements['udf'].split(',')\n",
    "            len_udf =len(udf_splitter)\n",
    "            if  len_udf==1 and udf==\"coalesce\":\n",
    "                coalesce_filler=str(columns[-1])\n",
    "                query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".\"+final_columns[0]+\".fillna(value=\"+coalesce_filler+',inplace=True)'\n",
    "                query_list.append(query)\n",
    "            elif len_udf==1 and udf==\"mul\":\n",
    "                list_of_col = [\"row.\"+a for a in final_columns]\n",
    "                cols='*'.join(list_of_col)\n",
    "                query = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+'.apply(lambda row: '+cols+', axis = 1)'\n",
    "                query_list.append(query)\n",
    "                \n",
    "            # THIS PART NEEDS TO BE REVISITED\n",
    "            elif len_udf==1 and udf==\"sum\":\n",
    "                columns=columns[0]\n",
    "                query= final_df+\"[`\"+columns+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                query_list.append(query)\n",
    "            \n",
    "            elif len_udf>1:\n",
    "                # here we need to consider a scenario where the udf is not more than2 udfs\n",
    "                for udf in reversed(udf_splitter):\n",
    "                    if udf =='mul':\n",
    "                        list_of_col = [\"row.\"+a for a in final_columns]\n",
    "                        cols='*'.join(list_of_col)\n",
    "                        query = final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+'.apply(lambda row: '+cols+', axis = 1)'\n",
    "                        query_list.append(query)\n",
    "                    elif udf=='coalesce':\n",
    "                        coalesce_filler=str(columns[-1])\n",
    "                        query =final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\".\"+final_columns[0]+\".fillna(value=\"+coalesce_filler+',inplace=True)'\n",
    "                        query_list.append(query) \n",
    "                    \n",
    "                    \n",
    "        else:\n",
    "            columns =list_elements['base_col']\n",
    "            alias=list_elements['Alias']\n",
    "            if alias=='':\n",
    "                query=final_df+\"[`\"+columns+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                query_list.append(query)\n",
    "            else:\n",
    "                query=final_df+\"[`\"+alias+\"`]\"+\"=\"+final_df+\"[`\"+columns+\"`]\"\n",
    "                query_list.append(query)\n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merge_crossover1_merge_crossover_merge_crossover2_df[`alpha`]=merge_crossover1_merge_crossover_merge_crossover2_df[`alpha`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df.crossover_rms.fillna(value=0,inplace=True)',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df.apply(lambda row: row.crossover_rms*row.crossover_gadr, axis = 1)',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df.crossover_rms.fillna(value=0,inplace=True)',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`mars`]=merge_crossover1_merge_crossover_merge_crossover2_df[`marsha`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`stay_year_ren`]=merge_crossover1_merge_crossover_merge_crossover2_df[`stay_year`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]=merge_crossover1_merge_crossover_merge_crossover2_df[`co_rev_goal`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal_adr`]=merge_crossover1_merge_crossover_merge_crossover2_df[`co_rn_goal_adr`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`def_otb`]=merge_crossover1_merge_crossover_merge_crossover2_df[`def_otb`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`def_rev`]=merge_crossover1_merge_crossover_merge_crossover2_df[`def_rev`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`def_adr`]=merge_crossover1_merge_crossover_merge_crossover2_df[`def_adr`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`target`]=merge_crossover1_merge_crossover_merge_crossover2_df[`target`]',\n",
       " 'merge_crossover1_merge_crossover_merge_crossover2_df[`avg_bkd`]=merge_crossover1_merge_crossover_merge_crossover2_df[`avg_bkd`]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = \"merge_crossover1_merge_crossover_merge_crossover2_df\"\n",
    "sql_dict = select_complex(select_list)\n",
    "panda_builder(final_df,sql_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROUP_BY PART ---07/06/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part will select the required col which needs to be grouped by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grp_cols(select_list):\n",
    "#     cols_udf= select_complex(select_list)\n",
    "#     col_list = []\n",
    "#     for item in cols_udf:\n",
    "#         if item['udf']!=\"sum\":\n",
    "#             name = item['base_col']\n",
    "#             if type(name)==str:\n",
    "#                 col_list.append(name)\n",
    "#             else:\n",
    "#                 col_list.append(name)\n",
    "#         else:\n",
    "#             pass\n",
    "#     list2 = []\n",
    "#     for x in col_list:\n",
    "#         list2 += x if type(x) == list else [x]\n",
    "#     grp_cols = [x for x in list2 if not isinstance(x, int)]\n",
    "#     final_cols = list(OrderedDict.fromkeys(grp_cols))\n",
    "#     return final_cols\n",
    "# grp_cols(select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crossover_rms',\n",
       " 'crossover_gadr',\n",
       " 'marsha',\n",
       " 'stay_year',\n",
       " 'co_rn_goal',\n",
       " 'co_rev_goal',\n",
       " 'co_rn_goal_adr',\n",
       " 'def_otb',\n",
       " 'def_rev',\n",
       " 'def_adr',\n",
       " 'target',\n",
       " 'avg_bkd']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grp_cols(group_section):\n",
    "    list1=[]\n",
    "    for i in group_section:\n",
    "        values =i['value']\n",
    "        list1.append(values)\n",
    "    return list1\n",
    "grp_cols(group_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part will select the cols which will go before agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_agg(select_list):\n",
    "    for i in select_list:\n",
    "        if i['udf']==\"sum\":\n",
    "            return i['base_col']\n",
    "        else:\n",
    "            pass\n",
    "group_agg(select_complex(select_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_func(final_df,query_dict,grp_cols,group_agg):\n",
    "    if 'groupby' in query_dict.keys():\n",
    "        abc = final_df+\"=\"+final_df+\".groupby(\"+str(grp_cols)+\")\"+str(group_agg)+\".agg(sum)\"\n",
    "    return abc\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"merge_crossover1_merge_crossover_merge_crossover2_df=merge_crossover1_merge_crossover_merge_crossover2_df.groupby(['crossover_rms', 'crossover_gadr', 'marsha', 'stay_year', 'co_rn_goal', 'co_rev_goal', 'co_rn_goal_adr', 'def_otb', 'def_rev', 'def_adr', 'target', 'avg_bkd'])['alpha'].agg(sum)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df=\"merge_crossover1_merge_crossover_merge_crossover2_df\"\n",
    "query_dict=query_dict\n",
    "grp_cols=grp_cols(group_section)\n",
    "group_agg=group_agg(select_complex(select_list))\n",
    "group_by_func(final_df,query_dict,grp_cols,group_agg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = final_df+\"=\"+\"final_df\"+\".groupby(\"+str(grp_cols)+\")\"+str(group_agg)+\".agg(sum)\"\n",
    "# abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_by_function(final_df,query_dict,group_section,group_agg):\n",
    "#     group_agg=group_agg(select_complex(select_list))\n",
    "#     group_agg=\n",
    "#     if 'groupby' in query_dict.keys():\n",
    "#         query = final_df+\"=\"+final_df+\"(\"+\n",
    "#     else:\n",
    "#         return panda_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = \"merge_crossover1_merge_crossover_merge_crossover2_df\"\n",
    "# group_by_function(final_df,query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_by_function(query_dict,panda_builder):\n",
    "#     if 'groupby' in query_dict.keys():\n",
    "#         print(\"yes\")\n",
    "#     else:\n",
    "#         return panda_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = \"merge_crossover1_merge_crossover_merge_crossover2_df\"\n",
    "# sql_dict = select_complex(select_list)\n",
    "# panda_builder(final_df,sql_dict)\n",
    "# group_by_function(query_dict,panda_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_complex(select_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_cols(select_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_udf= select_complex(select_list)\n",
    "# col_list = []\n",
    "# for item in cols_udf:\n",
    "#     name = item['base_col']\n",
    "#     if type(name)==str:\n",
    "#         col_list.append(name)\n",
    "#     else:\n",
    "#         col_list.append(name)\n",
    "# list2 = []\n",
    "# for x in col_list:\n",
    "#     list2 += x if type(x) == list else [x]\n",
    "# grp_cols = [x for x in list2 if not isinstance(x, int)]\n",
    "# print(grp_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# l1=['alpha','f','d',['alpha','beta',0]]\n",
    "# flatlist = list(itertools.chain(*l1))\n",
    "# flatlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from compiler.ast import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mylist =['a',0]\n",
    "# no_integers = [x for x in mylist if not isinstance(x, int)]\n",
    "# no_integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# t=['alpha', 'crossover_rms', 'crossover_rms', 'crossover_gadr', 'marsha', 'stay_year', 'co_rn_goal', 'co_rev_goal', 'co_rn_goal_adr', 'def_otb', 'def_rev', 'def_adr', 'target', 'avg_bkd']\n",
    "\n",
    "# a=list(OrderedDict.fromkeys(t))\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = ['crossover_rms',\n",
    "#  'crossover_gadr',\n",
    "#  'marsha',\n",
    "#  'stay_year',\n",
    "#  'co_rn_goal',\n",
    "#  'co_rev_goal',\n",
    "#  'co_rn_goal_adr',\n",
    "#  'def_otb',\n",
    "#  'def_rev',\n",
    "#  'def_adr',\n",
    "#  'target',\n",
    "#  'avg_bkd']\n",
    "# str(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =[\"alpha\"]\n",
    "# b =str(a)\n",
    "# c=\"ab\"\n",
    "# b+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
